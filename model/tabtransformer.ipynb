{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6975572c-253b-4e38-a8f2-0052b8082681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standard packages\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# # tf.disable_eager_execution()\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# import seaborn as sns\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "# from numpy import mean\n",
    "# from numpy import std\n",
    "# from IPython.display import Markdown, display\n",
    "\n",
    "# # Plotting \n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.patches import Rectangle\n",
    "# from matplotlib.patches import Patch\n",
    "# from matplotlib.lines import Line2D\n",
    "\n",
    "# # Sklearn\n",
    "# # from sklearn.cluster import KMeans\n",
    "# # from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import make_column_transformer\n",
    "# from sklearn.model_selection import GridSearchCV, train_test_split, ParameterGrid\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# ## accuracy metrics\n",
    "# from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score, matthews_corrcoef\n",
    "# from sklearn.metrics import recall_score, precision_score # for fairness metrics (calculate diff)\n",
    "# ## base estimators\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# # Fairness metrics\n",
    "# from aif360.metrics import BinaryLabelDatasetMetric\n",
    "# from aif360.metrics import ClassificationMetric\n",
    "# from aif360.sklearn.metrics import difference as aif_difference\n",
    "# # from aif360.sklearn.metrics import specificity_score, false_omission_rate_error\n",
    "# from aif360.sklearn.metrics import specificity_score\n",
    "# from aif360.sklearn.metrics import statistical_parity_difference, average_odds_difference, \\\n",
    "#                                    equal_opportunity_difference, average_odds_error\n",
    "# from aif360.sklearn.metrics import consistency_score, generalized_entropy_index, theil_index\n",
    "\n",
    "# # Explainers\n",
    "# from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# # Scalers\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Classifiers\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# # Bias mitigation techniques\n",
    "# # from aif360.algorithms.preprocessing import Reweighing\n",
    "# # from aif360.algorithms.preprocessing import OptimPreproc\n",
    "# # from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "# # from aif360.algorithms.preprocessing import LFR\n",
    "# from aif360.sklearn.preprocessing import Reweighing, ReweighingMeta, LearnedFairRepresentations\n",
    "# from aif360.sklearn.inprocessing import AdversarialDebiasing, ExponentiatedGradientReduction\n",
    "# from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, RejectOptionClassifier\n",
    "\n",
    "\n",
    "# # Set plot font\n",
    "# plt.rcParams.update({'font.family':'serif'})\n",
    "# plt.rcParams.update({'font.serif':'Times New Roman'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67febe95-dd8e-4564-8a5e-e641bb16906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 02:04:36.382337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-02 02:04:36.382366: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tabtransformertf.models.tabtransformer import TabTransformer\n",
    "from tabtransformertf.utils.preprocessing import df_to_dataset, build_categorical_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1baaaa70-1e74-4507-9e66-96bccca023b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1234\n",
    "tf.random.set_seed(random_state)\n",
    "# from numpy.random import seed\n",
    "# seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f89b597-3f3a-4079-bc7c-ad3fbf16dba8",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf71c09e-65a3-4ac7-b13b-4fa1bdfd6230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sex  age  race  juv_fel_count  juv_misd_count  juv_other_count  \\\n",
       "     race                                                                   \n",
       "4630 0       0   34     0              0               0                0   \n",
       "1952 1       0   40     1              0               0                0   \n",
       "740  0       1   26     0              0               0                0   \n",
       "4581 0       0   30     0              0               0                0   \n",
       "5122 1       1   20     1              0               0                0   \n",
       "\n",
       "           priors_count c_charge_degree  two_year_recid  \n",
       "     race                                                \n",
       "4630 0                8               M               1  \n",
       "1952 1                4               M               1  \n",
       "740  0                1               M               1  \n",
       "4581 0                5               M               1  \n",
       "5122 1                0               F               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_pickle('COMPAS_X')\n",
    "y = pd.read_pickle('COMPAS_y')\n",
    "data = pd.concat([X,y], axis=1)\n",
    "# .reset_index(drop=True)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=random_state)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391395d2-95ad-4f8a-a20f-044aac560d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'two_year_recid'\n",
    "X_train, y_train = train_data.drop(target_var, axis=1), train_data[target_var]\n",
    "X_test, y_test = test_data.drop(target_var, axis=1), test_data[target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e69e52-460c-4615-82f5-1a5cd0b35909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]2023-02-02 02:04:41.518776: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-02 02:04:41.518812: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-02 02:04:41.518841: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2023-02-02 02:04:41.519127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.38it/s]\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/tabtransformertf/utils/preprocessing.py:21: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  dataset[key] = value[:, tf.newaxis]\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/tabtransformertf/utils/preprocessing.py:27: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  dataset[key] = value[:, tf.newaxis]\n",
      "100%|██████████| 1/1 [00:00<00:00, 281.33it/s]\n"
     ]
    }
   ],
   "source": [
    "LABEL = y.name\n",
    "def get_num_cat_col(X_train, X_test, y_train , y_test):\n",
    "    train_data = pd.concat([X_train,y_train], axis=1)\n",
    "    test_data = pd.concat([X_test, y_test], axis=1)\n",
    "    NUMERIC_FEATURES = train_data.drop(LABEL, axis=1).select_dtypes(include=np.number).columns\n",
    "    CATEGORICAL_FEATURES = train_data.drop(LABEL, axis=1).select_dtypes(exclude=np.number).columns\n",
    "    \n",
    "    return train_data, test_data, NUMERIC_FEATURES, CATEGORICAL_FEATURES\n",
    "    \n",
    "def tf_dataset_for_TrainValTest(train_data, test_data):\n",
    "    LABEL = train_data.columns[-1]\n",
    "    FEATURES = list(NUMERIC_FEATURES) + list(CATEGORICAL_FEATURES)\n",
    "    # format dataset\n",
    "    for dataset in [train_data, test_data]:\n",
    "        dataset[LABEL] = dataset[LABEL].apply(lambda x: int(x)) \n",
    "        dataset[CATEGORICAL_FEATURES] = dataset[CATEGORICAL_FEATURES].astype(str)\n",
    "        dataset[NUMERIC_FEATURES] = dataset[NUMERIC_FEATURES].astype(float)\n",
    "    # Train/val split\n",
    "    train, val = train_test_split(train_data, test_size=0.2, random_state=random_state)\n",
    "    # Category preprocessing layers\n",
    "    category_prep_layers = build_categorical_prep(train, CATEGORICAL_FEATURES)\n",
    "    # To TF Dataset\n",
    "    train_dataset = df_to_dataset(train[FEATURES + [LABEL]], LABEL)\n",
    "    val_dataset = df_to_dataset(val[FEATURES + [LABEL]], LABEL, shuffle=False)  # No shuffle\n",
    "    test_dataset = df_to_dataset(test_data[FEATURES], shuffle=False) # No target, no shuffle\n",
    "    \n",
    "    return train, val, train_dataset, val_dataset, test_dataset\n",
    "train_data, test_data, NUMERIC_FEATURES, CATEGORICAL_FEATURES = get_num_cat_col(X_train, X_test, y_train , y_test)\n",
    "train, val, train_dataset, val_dataset, test_dataset = tf_dataset_for_TrainValTest(train_data, test_data)\n",
    "category_prep_layers = build_categorical_prep(train, CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bff333-3750-46c9-b687-3f06a8f43845",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420201d9-eb7d-4873-bae8-2296fef046c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Column information excluding label column and DT\n",
    "# LABEL = 'two_year_recid'\n",
    "# NUMERIC_FEATURES = train_data.drop(LABEL, axis=1).select_dtypes(include=np.number).columns\n",
    "# CATEGORICAL_FEATURES = train_data.drop(LABEL, axis=1).select_dtypes(exclude=np.number).columns\n",
    "\n",
    "# FEATURES = list(NUMERIC_FEATURES) + list(CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa2d685-44be-410a-89cf-acdd4a069adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # encoding as binary target\n",
    "# train_data[LABEL] = train_data[LABEL].apply(lambda x: int(x)) \n",
    "# test_data[LABEL] = test_data[LABEL].apply(lambda x: int(x))\n",
    "# train_data[LABEL].mean(), test_data[LABEL].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677298dc-05fe-47ef-b40a-f5b1d62e8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test_data.iloc[1:, :] # drop invalid row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25986888-5dc1-497c-96c7-bc5e5411c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set data types\n",
    "# train_data[CATEGORICAL_FEATURES] = train_data[CATEGORICAL_FEATURES].astype(str)\n",
    "# test_data[CATEGORICAL_FEATURES] = test_data[CATEGORICAL_FEATURES].astype(str)\n",
    "\n",
    "# train_data[NUMERIC_FEATURES] = train_data[NUMERIC_FEATURES].astype(float)\n",
    "# test_data[NUMERIC_FEATURES] = test_data[NUMERIC_FEATURES].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad185875-9f9e-43b2-9422-40fe9ff66d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train/test split\n",
    "# X_train, X_val = train_test_split(train_data, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee94e6d-446a-4485-a72f-fad23592ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ad92f-f1b9-46ad-9b61-831cbc903e22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelling Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1592a15a-cf05-4a35-ba46-69e877998d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Category preprocessing layers\n",
    "# category_prep_layers = build_categorical_prep(X_train, CATEGORICAL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bfdb641-4fec-4f2e-a84f-149a41e2a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To TF Dataset\n",
    "# train_dataset = df_to_dataset(X_train[FEATURES + [LABEL]], LABEL)\n",
    "# val_dataset = df_to_dataset(X_val[FEATURES + [LABEL]], LABEL, shuffle=False)  # No shuffle\n",
    "# test_dataset = df_to_dataset(test_data[FEATURES + [LABEL]], shuffle=False) # No target, no shuffle\n",
    "# # test_dataset = df_to_dataset(test_data[FEATURES], shuffle=False) # No target, no shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe05de6-639b-48b6-8387-e44be0d8db0c",
   "metadata": {},
   "source": [
    "## TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67528470-3cf1-4c6a-8b62-c701f7eb774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabtransformer = TabTransformer(\n",
    "    numerical_features = NUMERIC_FEATURES,\n",
    "    categorical_features = CATEGORICAL_FEATURES,\n",
    "    categorical_lookup=category_prep_layers,\n",
    "    embedding_dim=32,\n",
    "    out_dim=1,\n",
    "    out_activation='sigmoid',\n",
    "    depth=4,\n",
    "    heads=8,\n",
    "    attn_dropout=0.2,\n",
    "    ff_dropout=0.2,\n",
    "    mlp_hidden_factors=[2, 4],\n",
    "    use_column_embedding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e9a2389-2a47-422b-a365-002fb5c6fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "tabtransformer.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics= [tf.keras.metrics.AUC(name=\"PR AUC\", curve='PR')],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d6dfba2-3d79-45a2-ba1c-b954eda73432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 16s 290ms/step - loss: 0.8537 - PR AUC: 0.5287 - val_loss: 0.8771 - val_PR AUC: 0.5846\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.8170 - PR AUC: 0.5498 - val_loss: 0.8657 - val_PR AUC: 0.5902\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.8014 - PR AUC: 0.5514 - val_loss: 0.8524 - val_PR AUC: 0.5938\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.7813 - PR AUC: 0.5646 - val_loss: 0.8428 - val_PR AUC: 0.5972\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.7624 - PR AUC: 0.5830 - val_loss: 0.8223 - val_PR AUC: 0.6003\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.7614 - PR AUC: 0.5826 - val_loss: 0.7989 - val_PR AUC: 0.5996\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.7459 - PR AUC: 0.5901 - val_loss: 0.7852 - val_PR AUC: 0.5894\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.7376 - PR AUC: 0.6041 - val_loss: 0.7801 - val_PR AUC: 0.5941\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.7351 - PR AUC: 0.6032 - val_loss: 0.7748 - val_PR AUC: 0.5995\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.7374 - PR AUC: 0.5994 - val_loss: 0.7555 - val_PR AUC: 0.5976\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.7220 - PR AUC: 0.6112 - val_loss: 0.7434 - val_PR AUC: 0.5945\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.7257 - PR AUC: 0.6132 - val_loss: 0.7345 - val_PR AUC: 0.6023\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.7303 - PR AUC: 0.6062 - val_loss: 0.7279 - val_PR AUC: 0.6164\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.7202 - PR AUC: 0.6117 - val_loss: 0.7107 - val_PR AUC: 0.6415\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.7318 - PR AUC: 0.6022 - val_loss: 0.6967 - val_PR AUC: 0.6491\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.7193 - PR AUC: 0.6147 - val_loss: 0.6852 - val_PR AUC: 0.6481\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.7015 - PR AUC: 0.6336 - val_loss: 0.6792 - val_PR AUC: 0.6559\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 0.7082 - PR AUC: 0.6232 - val_loss: 0.6693 - val_PR AUC: 0.6460\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.7094 - PR AUC: 0.6284 - val_loss: 0.6610 - val_PR AUC: 0.6415\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 0.7073 - PR AUC: 0.6217 - val_loss: 0.6591 - val_PR AUC: 0.6379\n"
     ]
    }
   ],
   "source": [
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10, restore_best_weights=True)\n",
    "callback_list = [early]\n",
    "\n",
    "history = tabtransformer.fit(\n",
    "    train_dataset, \n",
    "    epochs=NUM_EPOCHS, \n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f62dea2-531c-4e8b-991c-37c1f5e73fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "test_preds = tabtransformer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7b97277-cfb9-4745-bd36-75b4050a66fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.473217  , 0.4295497 , 0.480947  , ..., 0.42363098, 0.42104703,\n",
       "       0.4809458 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = test_preds.reshape((test_preds.shape[0],))\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "010cf499-eb34-4cde-ba04-906fb9641c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "y_pred = (pred_prob >= threshold).astype('int')\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cf92496-b3a8-46cd-9cfe-5177575fe6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 944]\n",
      " [  1 286]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2852b3bf-73d4-46c5-9daf-289d9190168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.676\n",
      "Test PR AUC: 0.6789\n",
      "Test Accuracy: 0.5561\n",
      "Test F1: 0.4228\n"
     ]
    }
   ],
   "source": [
    "print(\"Test ROC AUC:\", np.round(roc_auc_score(test_data[LABEL], test_preds.ravel()), 4))\n",
    "print(\"Test PR AUC:\", np.round(average_precision_score(test_data[LABEL], test_preds.ravel()), 4))\n",
    "print(\"Test Accuracy:\", np.round(accuracy_score(test_data[LABEL], test_preds.ravel() > 0.5), 4))\n",
    "print(\"Test F1:\", np.round(f1_score(test_data[LABEL], test_preds.ravel() > 0.5), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158893a-cb28-4d1e-abeb-2af94ac2519d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
