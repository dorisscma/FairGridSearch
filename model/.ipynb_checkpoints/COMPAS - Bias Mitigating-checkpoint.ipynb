{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3047c60b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bias Mitigation Experiments - COMPAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2898f81",
   "metadata": {
    "id": "g97DX0X3nX0b"
   },
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861724cd",
   "metadata": {},
   "source": [
    "<!-- To return to the table of contents, click on the number at any major section heading.\n",
    "\n",
    "* [1. Prepare COMPAS data](#1.-Prepare-COMPAS-data)\n",
    "\n",
    "* [2. Training Baseline Models](#2.-Training-Baseline-Models)\n",
    "    * [2.1 Logistic Regression](#2.1-Learning-a-Logistic-Regression-(LR)-classifier-on-original-data)\n",
    "    * [2.2 Random Forest](#2.2-Learning-a-Random-Forest-(RF)-classifier-on-original-data)\n",
    "\n",
    "* [3. Bias mitigation using pre-processing technique](#3.-Bias-mitigation-using-pre-processing-technique)\n",
    "\n",
    "   * [3.1 Reweighing](#3.1-Reweighing)\n",
    "       * [3.1.1 RW on Logistic Regression](#3.1.1.-Learning-a-Logistic-Regression-(LR)-classifier-on-data-transformed-by-reweighing)\n",
    "       * [3.1.2 RW on Random Forest](#3.1.2.-Learning-a-Random-Forest-(RF)-classifier-on-data-transformed-by-reweighing)\n",
    "   * [3.2 Disparate impact remover ](#3.2-Disparate-impact-remover)\n",
    "       * [3.2.1 DIR on Logistic Regression](#3.2.1-Learning-a-Logistic-Regression-(LR)-classifier-on-data-transformed-by-DIR)\n",
    "       * [3.2.2 DIR on Random Forest](#3.2.2-Learning-a-Random-Forest-(RF)-classifier-on-data-transformed-by-DIR)\n",
    "  \n",
    "* [4. Bias mitigation using in-processing technique](#4.-Bias-mitigation-using-in-processing-technique)\n",
    "    * [4.1 Prejudice Remover (PR)](#4.1-Prejudice-Remover-(PR))\n",
    "    * [4.2 Adversarial Debiasing](#4.2-Adversarial-Debiasing)\n",
    "\n",
    "* [5. Bias mitigation using post-processing technique](#5.-Bias-mitigation-using-post-processing-technique)\n",
    "    * [5.1 Reject option classification (ROC)](#5.1-Reject-option-classification-(RejOpCl))\n",
    "        * [5.1.1 ROC on Logistic Regression](#5.1.1-Reject-option-classification-on-Logistic-Regression)\n",
    "        * [5.1.2 ROC on Random Forest](#5.1.2-Reject-option-classification-on-Random-Forest)\n",
    "    * [5.2 Equalized odds processor (EOPP)](#5.2-Equalized-odds-processor-(EqOddsPr))\n",
    "        * [5.2.1 EOPP on Logistic Regression](#5.2.1-Equalized-odds-processor-on-Logistic-Regression)\n",
    "        * [5.2.2 EOPP on Random Forest](#5.2.2-Equalized-odds-processor-on-Random-Forest)\n",
    "\n",
    "* [6. Summary of results](#6.-Summary-of-Model-Learning-Results)\n",
    "\n",
    "* [7. Analyze rates of different mitigators](#7.-Analyze-rates-of-different-mitigators)\n",
    "\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cfb0ed-8174-42b8-9edc-3aafcc2bb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6731f532",
   "metadata": {
    "id": "6731f532"
   },
   "outputs": [],
   "source": [
    "import helperfunctions as helpers\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# allow automatic reloading of changes in helperfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9286c6b-e965-4c75-a918-64e8d9224564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'rpy2': FairAdapt will be unavailable. To install, run:\n",
      "pip install 'aif360[FairAdapt]'\n",
      "WARNING:root:No module named 'torch': LearnedFairRepresentations will be unavailable. To install, run:\n",
      "pip install 'aif360[LFR]'\n"
     ]
    }
   ],
   "source": [
    "# Standard packages\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Plotting \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, ParameterGrid\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.sklearn.metrics import statistical_parity_difference, average_odds_difference, equal_opportunity_difference, average_odds_error\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio\n",
    "\n",
    "# Explainers\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from aif360.sklearn.preprocessing import ReweighingMeta\n",
    "from aif360.sklearn.inprocessing import AdversarialDebiasing\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Bias mitigation techniques\n",
    "# from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing import OptimPreproc\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "from aif360.algorithms.preprocessing import LFR\n",
    "\n",
    "# Set plot font\n",
    "plt.rcParams.update({'font.family':'serif'})\n",
    "plt.rcParams.update({'font.serif':'Times New Roman'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0501d7e-4ad8-4542-a696-4308277d068f",
   "metadata": {
    "id": "e50de4cd"
   },
   "source": [
    "## [1.](#Table-of-Contents) Prepare COMPAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7e4d95-edd7-4e39-b8cb-12c515e5089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "      <th>c_case_number</th>\n",
       "      <th>c_offense_date</th>\n",
       "      <th>c_arrest_date</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>c_charge_desc</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>r_case_number</th>\n",
       "      <th>r_charge_degree</th>\n",
       "      <th>r_days_from_arrest</th>\n",
       "      <th>r_offense_date</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>r_jail_in</th>\n",
       "      <th>r_jail_out</th>\n",
       "      <th>violent_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>vr_case_number</th>\n",
       "      <th>vr_charge_degree</th>\n",
       "      <th>vr_offense_date</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <th>type_of_assessment</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>screening_date</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2013-08-13 06:03:42</td>\n",
       "      <td>2013-08-14 05:41:20</td>\n",
       "      <td>13011352CF10A</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2013-01-26 03:45:27</td>\n",
       "      <td>2013-02-05 05:36:53</td>\n",
       "      <td>13001275CF10A</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>1</td>\n",
       "      <td>13009779CF10A</td>\n",
       "      <td>(F3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>13009779CF10A</td>\n",
       "      <td>(F3)</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2013-04-13 04:58:34</td>\n",
       "      <td>2013-04-14 07:02:04</td>\n",
       "      <td>13005330CF10A</td>\n",
       "      <td>2013-04-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>1</td>\n",
       "      <td>13011511MM10A</td>\n",
       "      <td>(M1)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13000570CF10A</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12014130CF10A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>76.0</td>\n",
       "      <td>F</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  juv_fel_count  \\\n",
       "0  1947-04-18   69  Greater than 45             Other              0   \n",
       "1  1982-01-22   34          25 - 45  African-American              0   \n",
       "2  1991-05-14   24     Less than 25  African-American              0   \n",
       "3  1993-01-21   23     Less than 25  African-American              0   \n",
       "4  1973-01-22   43          25 - 45             Other              0   \n",
       "\n",
       "   decile_score  juv_misd_count  juv_other_count  priors_count  \\\n",
       "0             1               0                0             0   \n",
       "1             3               0                0             0   \n",
       "2             4               0                1             4   \n",
       "3             8               1                0             1   \n",
       "4             1               0                0             2   \n",
       "\n",
       "   days_b_screening_arrest            c_jail_in           c_jail_out  \\\n",
       "0                     -1.0  2013-08-13 06:03:42  2013-08-14 05:41:20   \n",
       "1                     -1.0  2013-01-26 03:45:27  2013-02-05 05:36:53   \n",
       "2                     -1.0  2013-04-13 04:58:34  2013-04-14 07:02:04   \n",
       "3                      NaN                  NaN                  NaN   \n",
       "4                      NaN                  NaN                  NaN   \n",
       "\n",
       "   c_case_number c_offense_date c_arrest_date  c_days_from_compas  \\\n",
       "0  13011352CF10A     2013-08-13           NaN                 1.0   \n",
       "1  13001275CF10A     2013-01-26           NaN                 1.0   \n",
       "2  13005330CF10A     2013-04-13           NaN                 1.0   \n",
       "3  13000570CF10A     2013-01-12           NaN                 1.0   \n",
       "4  12014130CF10A            NaN    2013-01-09                76.0   \n",
       "\n",
       "  c_charge_degree                   c_charge_desc  is_recid  r_case_number  \\\n",
       "0               F    Aggravated Assault w/Firearm         0            NaN   \n",
       "1               F  Felony Battery w/Prior Convict         1  13009779CF10A   \n",
       "2               F           Possession of Cocaine         1  13011511MM10A   \n",
       "3               F          Possession of Cannabis         0            NaN   \n",
       "4               F           arrest case no charge         0            NaN   \n",
       "\n",
       "  r_charge_degree  r_days_from_arrest r_offense_date  \\\n",
       "0             NaN                 NaN            NaN   \n",
       "1            (F3)                 NaN     2013-07-05   \n",
       "2            (M1)                 0.0     2013-06-16   \n",
       "3             NaN                 NaN            NaN   \n",
       "4             NaN                 NaN            NaN   \n",
       "\n",
       "                 r_charge_desc   r_jail_in  r_jail_out  violent_recid  \\\n",
       "0                          NaN         NaN         NaN            NaN   \n",
       "1  Felony Battery (Dom Strang)         NaN         NaN            NaN   \n",
       "2  Driving Under The Influence  2013-06-16  2013-06-16            NaN   \n",
       "3                          NaN         NaN         NaN            NaN   \n",
       "4                          NaN         NaN         NaN            NaN   \n",
       "\n",
       "   is_violent_recid vr_case_number vr_charge_degree vr_offense_date  \\\n",
       "0                 0            NaN              NaN             NaN   \n",
       "1                 1  13009779CF10A             (F3)      2013-07-05   \n",
       "2                 0            NaN              NaN             NaN   \n",
       "3                 0            NaN              NaN             NaN   \n",
       "4                 0            NaN              NaN             NaN   \n",
       "\n",
       "                vr_charge_desc  type_of_assessment  decile_score.1 score_text  \\\n",
       "0                          NaN  Risk of Recidivism               1        Low   \n",
       "1  Felony Battery (Dom Strang)  Risk of Recidivism               3        Low   \n",
       "2                          NaN  Risk of Recidivism               4        Low   \n",
       "3                          NaN  Risk of Recidivism               8       High   \n",
       "4                          NaN  Risk of Recidivism               1        Low   \n",
       "\n",
       "  screening_date v_type_of_assessment  v_decile_score v_score_text  \\\n",
       "0     2013-08-14     Risk of Violence               1          Low   \n",
       "1     2013-01-27     Risk of Violence               1          Low   \n",
       "2     2013-04-14     Risk of Violence               3          Low   \n",
       "3     2013-01-13     Risk of Violence               6       Medium   \n",
       "4     2013-03-26     Risk of Violence               1          Low   \n",
       "\n",
       "  v_screening_date  in_custody out_custody  priors_count.1  start   end  \\\n",
       "0       2013-08-14  2014-07-07  2014-07-14               0      0   327   \n",
       "1       2013-01-27  2013-01-26  2013-02-05               0      9   159   \n",
       "2       2013-04-14  2013-06-16  2013-06-16               4      0    63   \n",
       "3       2013-01-13         NaN         NaN               1      0  1174   \n",
       "4       2013-03-26         NaN         NaN               2      0  1102   \n",
       "\n",
       "   event  two_year_recid  \n",
       "0      0               0  \n",
       "1      1               1  \n",
       "2      0               1  \n",
       "3      0               0  \n",
       "4      0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data as pandas data frame\n",
    "df = pd.read_csv(\"../data/Compas/compas-scores-two-years.csv\")\n",
    "# check columns\n",
    "pd.set_option('display.max_columns', None) # expand all columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a5f798-04a0-475a-9ff0-73499010cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3696\n",
       "Caucasian           2454\n",
       "Hispanic             637\n",
       "Other                377\n",
       "Asian                 32\n",
       "Native American       18\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select features of interest\n",
    "df = df[['sex','age','race','juv_fel_count','juv_misd_count','juv_other_count','priors_count','c_charge_degree', 'two_year_recid']]\n",
    "\n",
    "# unique values of the protected feature race\n",
    "df['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5092b30d-08d9-49b5-be4a-6ca11e80c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode protected features \n",
    "\n",
    "# make race (=protected attribute) a binary variable\n",
    "array = ['Caucasian', 'African-American'] # only include samples corresponding to Caucasian or African-American\n",
    "df = df.loc[df['race'].isin(array)]\n",
    "\n",
    "def protected_race(row):\n",
    "    if row['race'] == 'Caucasian':\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "df['race'] = df.apply(protected_race, axis=1)\n",
    "\n",
    "# make sex a binary variable\n",
    "def protected_sex(row):\n",
    "    if row['sex'] == 'Female': # female is the privileged group in this case\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "df['sex'] = df.apply(protected_sex, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e01277-7348-476f-9a7b-f4adb7cac52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of object features\n",
    "categorical_cols = list(df.select_dtypes(exclude=[np.number]).columns)\n",
    "df = pd.get_dummies(df, columns = categorical_cols)\n",
    "\n",
    "# encode binary feature: c_charge \n",
    "df = df.drop(['c_charge_degree_F'], axis=1)\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752bce7e-8855-41cf-9e20-d12488a2fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip labels to ensure pos_label = 1, not becoming recidivist\n",
    "df['two_year_recid'] = (~df['two_year_recid'].astype(bool)).astype(int)\n",
    "\n",
    "# select descriptive features and target variable\n",
    "X = df.loc[:, df.columns != 'two_year_recid'] # select all features but target feature\n",
    "y = df[['race', 'two_year_recid']] # include protected feature in order to AIF360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25456585-45b4-4660-a6b0-edaf7c1f3d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set protected attribute as index\n",
    "X = X.set_index(['race'], append = True, drop = False)\n",
    "y = y.set_index(['race'], append = True)\n",
    "\n",
    "# make y data frames to 1d array to pass modeling, but keep index (protected attribute)\n",
    "y = pd.Series(y['two_year_recid'], index=y.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94e35f",
   "metadata": {},
   "source": [
    "## [2.](#Table-of-Contents) Proposed GridSearch Approach "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372cad1-371f-4c03-aced-2970b97a0597",
   "metadata": {},
   "source": [
    "The GridSearch Approach includes hyperparameter, threshold, and Bias Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23a88eed-9c2c-4ac8-b9e7-526d01e1036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_metrics(y_test, y_pred, pred_prob, thres_dict, threshold):\n",
    "    \"\"\"Returns a dictionary with all interested accuracy and fairness metrics.\n",
    "        Args:\n",
    "            y_test (array-like): true labels from test set.\n",
    "            y_pred (array-like): predicted labels for test set.\n",
    "            thres_dict (dict): dictionary that stores all info.\n",
    "            threshold (np.float): given threshold used to obtain y_pred.\n",
    "        Returns:\n",
    "            dict: `thres_dict`\n",
    "    \"\"\"\n",
    "    \n",
    "    # evaluate model performance for each split\n",
    "    thres_dict[threshold]['acc_score'] += [accuracy_score(y_test, y_pred)]\n",
    "    thres_dict[threshold]['bacc_score'] += [balanced_accuracy_score(y_test, y_pred)]\n",
    "    thres_dict[threshold]['f1_score'] += [f1_score(y_test, y_pred)]\n",
    "    thres_dict[threshold]['auc_score'] += [roc_auc_score(y_test, pred_prob)]\n",
    "    thres_dict[threshold]['spd_score'] += [statistical_parity_difference(y_test, y_pred, prot_attr='race')]\n",
    "    thres_dict[threshold]['aod_score'] += [average_odds_difference(y_test, y_pred, prot_attr='race')]\n",
    "\n",
    "    return thres_dict\n",
    "\n",
    "def get_avg_metrics(thres_dict):\n",
    "    \"\"\"Returns the average of all cv splits from the same model setting (hyperparameter and threshold).\n",
    "    Args:\n",
    "        thres_dict (dict): the dictionary with all info on each cv split.\n",
    "    Returns:\n",
    "        dict: `final_metrics`\n",
    "    \"\"\" \n",
    "    import copy\n",
    "    # calculate the average for each metrics from all splits\n",
    "    avg_metrics = copy.deepcopy(thres_dict)\n",
    "    for threshold in avg_metrics.keys(): \n",
    "        average_list = {}\n",
    "        for metric in avg_metrics[threshold].keys():\n",
    "            average_list['avg_%s'%metric] = mean(avg_metrics[threshold][metric])\n",
    "        avg_metrics[threshold]['average'] = average_list\n",
    "    return avg_metrics\n",
    "\n",
    "def get_output_table(all_metrics, base):\n",
    "    \"\"\"Returns the output table from all param_grid.\n",
    "    Args:\n",
    "        all_metrics (dict): the final dictionary with info from all param_grid.\n",
    "        base (str): the name of the base estimator that is shown in the output table.\n",
    "    \"\"\" \n",
    "\n",
    "    output_table = pd.DataFrame()\n",
    "    for model in all_metrics.keys():\n",
    "        all_metrics[model]['parameters']['hparam'].pop('random_state', None)\n",
    "        table_cv = pd.DataFrame(all_metrics[model]['metrics']['average'], index=[0])\n",
    "        table_cv.insert(0, 'model', base)\n",
    "        table_cv.insert(1, 'param', str(all_metrics[model]['parameters']['hparam']))\n",
    "        table_cv.insert(2, 'Bias_Mitigation', str(all_metrics[model]['parameters']['Bias_Mitigation']))\n",
    "        table_cv.insert(3, 'threshold', all_metrics[model]['parameters']['threshold'])\n",
    "        output_table = pd.concat([output_table, table_cv]).reset_index(drop=True)\n",
    "        \n",
    "    output_table.Bias_Mitigation = output_table.Bias_Mitigation.replace({'no_BM':''})\n",
    "    return output_table\n",
    "\n",
    "def style_table(df):\n",
    "    \"\"\"Returs the output table with highlight on the best metrics\n",
    "    Args:\n",
    "        df (DataFrame): the output table to be styled\n",
    "    \"\"\"\n",
    "    accuracy_metrics = ['avg_'+col for col in ['acc_score', 'bacc_score', 'f1_score', 'auc_score']]\n",
    "    fairness_metrics = ['avg_'+col for col in ['spd_score', 'aod_score']]\n",
    "\n",
    "\n",
    "    df = df.style.highlight_max(subset=accuracy_metrics,color='lightgreen')\\\n",
    "                   .apply(lambda s: ['background: yellow' if abs(cell)==min(abs(s)) else '' for cell in s], subset=fairness_metrics)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e600da1a-b16e-4581-bd57-1b34d239a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# param_grid = {'hyperp_grid': {'solver':['lbfgs', 'sag']}, \n",
    "#               'threshold': np.linspace(0.3, 0.7, 2),\n",
    "#               'Bias_Mitigation':[None]}\n",
    "# thres_arr = param_grid['threshold']\n",
    "# BM_arr = param_grid['Bias_Mitigation']\n",
    "# param = list(ParameterGrid(param_grid['hyperp_grid']))[i]\n",
    "# thres_BM_dict = {}\n",
    "# # logistic regression classifier with stratified kfold cross validation\n",
    "# skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "# thres_dict = {threshold: {'acc_score':[], 'bacc_score': [], 'f1_score': [], 'auc_score': [], 'spd_score': [], 'aod_score': []}\\\n",
    "#               for threshold in thres_arr}\n",
    "\n",
    "# for train_index, test_index in skf.split(X, y):\n",
    "#     X_train, X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "#     y_train , y_test = y[train_index] , y[test_index]\n",
    "\n",
    "#     # normalize data features, fit on training set to avoid data leakage\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X_train[X_train.columns])\n",
    "#     X_train[X_train.columns] = scaler.transform(X_train[X_train.columns])\n",
    "#     X_test[X_test.columns] = scaler.transform(X_test[X_test.columns])\n",
    "\n",
    "#     model = ReweighingMeta(estimator=LogisticRegression(**param))\n",
    "#     model.fit(X_train,y_train)\n",
    "#     for threshold in thres_arr:\n",
    "#         pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "#         y_pred = (pred_prob >= threshold).astype('int') # set threshold\n",
    "\n",
    "#         thres_dict = store_metrics(y_test, y_pred, thres_dict, threshold)\n",
    "#     avg_metrics = get_avg_metrics(thres_dict)\n",
    "#     # thres_BM_dict[BM_name] = avg_metrics\n",
    "\n",
    "\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a988917-bc27-42b2-9a44-1fd3ddbafc01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# old\n",
    "# class skf_model():\n",
    "#     def __init__(self, cv, report, random_state):\n",
    "#         self.cv = cv\n",
    "#         self.report = report\n",
    "#         self.random_state = random_state\n",
    "        \n",
    "#     # @methods\n",
    "#     def get_metrics(self, X, y, base='LR', param = {}, BM_arr=[None], thres_arr=[0.5]):\n",
    "#         # logistic regression classifier with stratified kfold cross validation\n",
    "#         skf = StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=self.random_state)\n",
    "#         thres_dict = {threshold: {'acc_score':[], 'bacc_score': [], 'f1_score': [], 'auc_score': [],\n",
    "#                                   'spd_score': [], 'aod_score': []}\\\n",
    "#                       for threshold in thres_arr}\n",
    "#         thres_BM_dict = {}\n",
    "        \n",
    "#         for train_index, test_index in skf.split(X, y):\n",
    "#             X_train, X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "#             y_train , y_test = y[train_index] , y[test_index]\n",
    "\n",
    "#             # normalize data features, fit on training set to avoid data leakage\n",
    "#             scaler = StandardScaler()\n",
    "#             scaler.fit(X_train[X_train.columns])\n",
    "#             X_train[X_train.columns] = scaler.transform(X_train[X_train.columns])\n",
    "#             X_test[X_test.columns] = scaler.transform(X_test[X_test.columns])\n",
    "\n",
    "#             # fit model\n",
    "#             param.update({'random_state': self.random_state})\n",
    "#             if base=='LR':\n",
    "#                 base_estimator=LogisticRegression(**param)\n",
    "#             elif base=='RF':\n",
    "#                 base_estimator=RandomForestClassifier(**param)\n",
    "                \n",
    "#             for BM in BM_arr:\n",
    "#                 BM_name = BM\n",
    "#                 if BM == None:\n",
    "#                     BM_name = 'no_BM'\n",
    "#                     model = base_estimator\n",
    "#                 elif BM == 'RW':\n",
    "#                     model = ReweighingMeta(estimator=base_estimator)\n",
    "#                 elif BM == 'AD':\n",
    "#                     model = AdversarialDebiasing(prot_attr='race', random_state=self.random_state)\n",
    "\n",
    "#                 model.fit(X_train,y_train)\n",
    "#                 for threshold in thres_arr:\n",
    "#                     pred_prob = model.predict_proba(X_test)[:,1]\n",
    "#                     y_pred = (pred_prob >= threshold).astype('int') # set threshold\n",
    "\n",
    "#                     thres_dict = store_metrics(y_test, y_pred, pred_prob, thres_dict, threshold)\n",
    "#                 avg_metrics = get_avg_metrics(thres_dict)\n",
    "#                 thres_BM_dict[BM_name] = avg_metrics\n",
    "\n",
    "#         return thres_BM_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecf25ef8-99e3-463b-9ea1-88dafecfffef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class skf_model():\n",
    "    def __init__(self, cv, random_state):\n",
    "        self.cv = cv\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    # @methods\n",
    "    def get_metrics(self, X, y, base='LR', param = {}, BM_arr=[None], thres_arr=[0.5]):\n",
    "        # logistic regression classifier with stratified kfold cross validation\n",
    "        skf = StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=self.random_state)\n",
    "        thres_dict = {threshold: {'acc_score':[], 'bacc_score': [], 'f1_score': [], 'auc_score': [],\n",
    "                                  'spd_score': [], 'aod_score': []}\\\n",
    "                      for threshold in thres_arr}\n",
    "        thres_BM_dict = {}\n",
    "        \n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "            y_train , y_test = y[train_index] , y[test_index]\n",
    "\n",
    "            # normalize data features, fit on training set to avoid data leakage\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train[X_train.columns])\n",
    "            X_train[X_train.columns] = scaler.transform(X_train[X_train.columns])\n",
    "            X_test[X_test.columns] = scaler.transform(X_test[X_test.columns])\n",
    "\n",
    "            # fit model\n",
    "            param.update({'random_state': self.random_state})\n",
    "            if base=='LR':\n",
    "                base_estimator=LogisticRegression(**param)\n",
    "            elif base=='RF':\n",
    "                base_estimator=RandomForestClassifier(**param)\n",
    "                \n",
    "            for BM in BM_arr:\n",
    "                BM_name = BM\n",
    "                if BM == None:\n",
    "                    BM_name = 'no_BM'\n",
    "                    model = base_estimator\n",
    "                elif BM == 'RW':\n",
    "                    model = ReweighingMeta(estimator=base_estimator)\n",
    "                elif BM == 'AD':\n",
    "                    model = AdversarialDebiasing(prot_attr='race', random_state=self.random_state)\n",
    "\n",
    "                model.fit(X_train,y_train)\n",
    "                for threshold in thres_arr:\n",
    "                    pred_prob = model.predict_proba(X_test)[:,1]\n",
    "                    y_pred = (pred_prob >= threshold).astype('int') # set threshold\n",
    "\n",
    "                    thres_dict = store_metrics(y_test, y_pred, pred_prob, thres_dict, threshold)\n",
    "                avg_metrics = get_avg_metrics(thres_dict)\n",
    "                thres_BM_dict[BM_name] = avg_metrics\n",
    "\n",
    "        return thres_BM_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e584780-e988-4f9b-ae8b-8a876a5c49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridsearchCV_LRC():\n",
    "    def __init__(self,param_grid, cv=10, random_state=1234):\n",
    "        self.param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X=X, y=y, random_state=1234):\n",
    "        \"\"\"Run fit with all sets of parameters.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training vector, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "        y : array-like of shape (n_samples, n_output) \\\n",
    "            or (n_samples,), default=None\n",
    "            Target relative to X for classification or regression;\n",
    "            None for unsupervised learning.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Instance of fitted estimator.\n",
    "        \"\"\"\n",
    "\n",
    "        base = 'LR'\n",
    "        if 'hyperp_grid' in self.param_grid: \n",
    "            hyperp_grid = list(ParameterGrid(param_grid['hyperp_grid']))\n",
    "        else: hyperp_grid = [{'penalty':'l2'}] # default setting    \n",
    "        if 'Bias_Mitigation' not in self.param_grid: \n",
    "            param_grid['Bias_Mitigation'] = [None]        \n",
    "        if 'threshold' not in self.param_grid: \n",
    "            param_grid['threshold'] = [0.5]\n",
    "\n",
    "        all_metrics = {}\n",
    "        for i, param in enumerate(tqdm(hyperp_grid)):\n",
    "            print(param)\n",
    "            model = skf_model(self.cv, self.random_state)\n",
    "            metrics = model.get_metrics(X=X, y=y, base=base, param=param, \n",
    "                                        BM_arr=param_grid['Bias_Mitigation'], thres_arr=param_grid['threshold'])\n",
    "            # print(metrics)\n",
    "            for j, BM in enumerate(metrics.keys()):\n",
    "                for k,thres in enumerate(metrics[BM].keys()):\n",
    "                    all_param = {'hparam':param, 'Bias_Mitigation':BM, 'threshold':thres}\n",
    "                    all_metrics['LR_%s%s%s'%(i,j,k)] = {'parameters':all_param, 'metrics':metrics[BM][thres]}\n",
    "                    \n",
    "        self.all_metrics = all_metrics\n",
    "        self.output_table = get_output_table(all_metrics, base=base)\n",
    "\n",
    "        param_col = ['model','param','Bias_Mitigation','threshold']\n",
    "        self._best_index = np.argmax(self.output_table.avg_acc_score)\n",
    "        self._best_param = self.output_table.loc[self._best_index, param_col]\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4386ffb-3a79-44bb-aef7-a5ef4f545771",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 1/2 [00:43<00:43, 43.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [01:27<00:00, 43.82s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_output_table() got an unexpected keyword argument 'base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperp_grid\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m]},\n\u001b[1;32m      5\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m11\u001b[39m),\n\u001b[1;32m      6\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBias_Mitigation\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRW\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m      7\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridsearchCV_LRC(param_grid\u001b[38;5;241m=\u001b[39mparam_grid)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m, in \u001b[0;36mGridsearchCV_LRC.fit\u001b[0;34m(self, X, y, random_state)\u001b[0m\n\u001b[1;32m     43\u001b[0m             all_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(i,j,k)] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m:all_param, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m:metrics[BM][thres]}\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_metrics \u001b[38;5;241m=\u001b[39m all_metrics\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_table \u001b[38;5;241m=\u001b[39m \u001b[43mget_output_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m param_col \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBias_Mitigation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_table\u001b[38;5;241m.\u001b[39mavg_acc_score)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_output_table() got an unexpected keyword argument 'base'"
     ]
    }
   ],
   "source": [
    "# param_grid = {'hyperp_grid': {'C':[1, 10],'solver':['liblinear', 'saga'],'penalty':['l1','l2']}, \n",
    "#               'threshold': np.linspace(0.3, 0.7, 7),\n",
    "#               'Bias_Mitigation':[None,'RW','AD']}\n",
    "param_grid = {'hyperp_grid': {'C':[0.1, 1]},\n",
    "              'threshold': np.linspace(0.3, 0.7, 11),\n",
    "              'Bias_Mitigation':[None,'RW']}\n",
    "clf = GridsearchCV_LRC(param_grid=param_grid)\n",
    "clf.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad4c941-b761-49d8-b76f-c07b9ba5cfbf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = clf.output_table\n",
    "print(clf._best_param)\n",
    "style_table(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b9888-57bc-47cf-a5d6-a4ebd91b2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "results.plot(x=\"avg_acc_score\", y=\"avg_spd_score\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543bc35f-7a5d-46e5-b1df-784918c409d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridsearchCV_RFC():\n",
    "    def __init__(self, param_grid, cv=10, random_state=1234):\n",
    "        self.param_grid = param_grid\n",
    "        self.cv = cv\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X=X, y=y, random_state=1234):\n",
    "        \"\"\"Run fit with all sets of parameters.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training vector, where `n_samples` is the number of samples and\n",
    "            `n_features` is the number of features.\n",
    "        y : array-like of shape (n_samples, n_output) \\\n",
    "            or (n_samples,), default=None\n",
    "            Target relative to X for classification or regression;\n",
    "            None for unsupervised learning.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Instance of fitted estimator.\n",
    "        \"\"\"\n",
    "        \n",
    "        base = 'RF'\n",
    "        if 'hyperp_grid' in self.param_grid: \n",
    "            hyperp_grid = list(ParameterGrid(param_grid['hyperp_grid']))\n",
    "        else: hyperp_grid = [{'penalty':'l2'}] # default setting    \n",
    "        if 'Bias_Mitigation' not in self.param_grid: \n",
    "            param_grid['Bias_Mitigation'] = [None]        \n",
    "        if 'threshold' not in self.param_grid: \n",
    "            param_grid['threshold'] = [0.5]\n",
    "\n",
    "        all_metrics = {}\n",
    "        for i, param in enumerate(tqdm(hyperp_grid)):\n",
    "            print(param)\n",
    "            model = skf_model(self.cv, random_state)\n",
    "            metrics = model.get_metrics(X=X, y=y, base=base, param=param, \n",
    "                                        BM_arr=param_grid['Bias_Mitigation'], thres_arr=param_grid['threshold'])\n",
    "            # print(metrics)\n",
    "            for j, BM in enumerate(metrics.keys()):\n",
    "                for k,thres in enumerate(metrics[BM].keys()):\n",
    "                    all_param = {'hparam':param, 'Bias_Mitigation':BM, 'threshold':thres}\n",
    "                    all_metrics['LR_%s%s%s'%(i,j,k)] = {'parameters':all_param, 'metrics':metrics[BM][thres]}\n",
    "\n",
    "           \n",
    "        self.all_metrics = all_metrics\n",
    "        self.output_table = get_output_table(all_metrics, base=base)\n",
    "\n",
    "        param_col = ['model','param','Bias_Mitigation','threshold']\n",
    "        self._best_index = np.argmax(self.output_table.avg_acc_score)\n",
    "        self._best_param = self.output_table.loc[self._best_index, param_col]\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9af7a-7a24-499a-9921-0d43f5c037b1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# param_grid = {'hyperp_grid': {'n_estimators':[10, 100],'criterion':['gini', 'entropy'], 'max_depth':[8, None]}, \n",
    "#               'threshold': np.linspace(0.3, 0.7, 7),\n",
    "#               'Bias_Mitigation':[None,'RW','AD']}\n",
    "param_grid = {'hyperp_grid': {'n_estimators':[10, 100]},\n",
    "              'threshold': np.linspace(0.3, 0.7, 11),\n",
    "              'Bias_Mitigation':[None,'RW']}\n",
    "clf_RF = GridsearchCV_RFC(param_grid=param_grid)\n",
    "clf_RF.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184652e9-8603-4ead-87cb-335fc5388236",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_RF = clf_RF.output_table\n",
    "print(clf_RF._best_param)\n",
    "style_table(results_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e676d-83f6-4060-9228-cbd21829141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "results_RF.plot(x=\"avg_acc_score\", y=\"avg_spd_score\", kind=\"scatter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217e52c-c17d-4874-ba4f-ff4d46132dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COMPAS - Bias Mitigating.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
